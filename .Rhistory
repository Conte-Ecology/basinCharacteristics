source( file.path(baseDirectory, "scripts", "HRD_INPUTS.txt") )
# ===================================
# Replace percentAreaWithData columns
# ===================================
# Local files
indLocal <- read.csv(file.path(baseDirectory, "versions", outputName, "rTables", paste0("local_forest_", statType, ".csv")))
depLocal <- read.csv(file.path(baseDirectory, "versions", outputName, "rTables", paste0("local_undev_forest_", statType, ".csv")))
depLocalOut <- select(depLocal, -percentAreaWithData)%>%
left_join(select(indLocal, -MEAN), by = zoneField)
write.csv(depLocalOut, file = file.path(baseDirectory, "versions", outputName, "rTables", paste0("local_undev_forest_", statType, ".csv")))
# Upstream Files
indUpstream <- read.csv(file.path(baseDirectory, "versions", outputName, "rTables", paste0("upstream_forest_", statType, ".csv")))
depUpstream <- read.csv(file.path(baseDirectory, "versions", outputName, "rTables", paste0("upstream_undev_forest_", statType, ".csv")))
depUpstreamOut <- select(depUpstream, -percentAreaWithData)%>%
left_join(select(indUpstream, -MEAN), by = zoneField)
write.csv(depUpstreamOut, file = file.path(baseDirectory, "versions", outputName, "rTables", paste0("upstream_undev_forest_", statType, ".csv")))
rm(list = ls())
library(foreign)
library(dplyr)
path <- "C:/KPONEIL/riparianBufferErrors/dbfTables"
A <- read.dbf(file.path(path, "forest_HUC010801_50ft.dbf"))
names(A)[2:4] <- paste0(names(A)[2:4], "_50ft")
B <- read.dbf(file.path(path, "forest_HUC010801_100ft.dbf"))
names(B)[2:4] <- paste0(names(B)[2:4], "_100ft")
C <- read.dbf(file.path(path, "forest_HUC010801_200ft.dbf"))
names(C)[2:4] <- paste0(names(C)[2:4], "_200ft")
D <- left_join(A, B, by = "FEATUREID") %>%
left_join(C, by = "FEATUREID")
int <- D[which(D$AREA_50ft == D$AREA_200ft),]
out <- D[which(D$AREA_50ft != D$AREA_200ft),]
int
out
path
int
path <- "C:/KPONEIL/GitHub/projects/basinCharacteristics/zonalStatistics/gisFiles/versions/riparianBuffers/processingTables"
G <- read.dbf(file.path(path, "forest_HUC010801_200ft.dbf"))
names(G)[2:4] <- paste0(names(G)[2:4], "_200ft")
E <- left_join(C, G, by = "FEATUREID")
head(E)
int <- E[which(E$AREA_200ft.x == E$AREA_200ft.y),]
int
int <- E[which(E$AREA_200ft.x != E$AREA_200ft.y),]
int
int <- D[which(D$AREA_50ft == D$AREA_200ft),]
int
C <- read.dbf(file.path(path, "forest_HUC010801_200ft2.dbf"))
names(C)[2:4] <- paste0(names(C)[2:4], "_200ft")
D <- left_join(A, B, by = "FEATUREID") %>%
left_join(C, by = "FEATUREID")
int <- D[which(D$AREA_50ft == D$AREA_200ft),]
int
path <- "C:/KPONEIL/riparianBufferErrors/dbfTables"
C <- read.dbf(file.path(path, "forest_HUC010801_200ft2.dbf"))
names(C)[2:4] <- paste0(names(C)[2:4], "_200ft")
D <- left_join(A, B, by = "FEATUREID") %>%
left_join(C, by = "FEATUREID")
int <- D[which(D$AREA_50ft == D$AREA_200ft),]
out <- D[which(D$AREA_50ft != D$AREA_200ft),]
int
G <- read.dbf(file.path(path, "forest_HUC010801_200ft.dbf"))
names(G)[2:4] <- paste0(names(G)[2:4], "_200ft")
E <- left_join(C, G, by = "FEATUREID")
int <- E[which(E$AREA_200ft.x != E$AREA_200ft.y),]
int
int <- E[which(E$AREA_200ft.x == E$AREA_200ft.y),]
int
path <- "C:/KPONEIL/riparianBufferErrors/dbfTables"
A <- read.dbf(file.path(path, "forest_HUC010801_50ft2.dbf"))
names(A)[2:4] <- paste0(names(A)[2:4], "_50ft")
C <- read.dbf(file.path(path, "forest_HUC010801_200ft2.dbf"))
names(C)[2:4] <- paste0(names(C)[2:4], "_200ft")
D <- left_join(A, B, by = "FEATUREID")
D <- left_join(A, B, by = "FEATUREID") %>%
left_join(C, by = "FEATUREID")
int <- D[which(D$AREA_50ft == D$AREA_200ft),]
int
int <- D[which(D$AREA_50ft >= D$AREA_200ft),]
int
dim(int)
path <- "C:/KPONEIL/riparianBufferErrors/dbfTables"
A <- read.dbf(file.path(path, "forest_HUC010801_50ft2.dbf"))
names(A)[2:4] <- paste0(names(A)[2:4], "_50ft")
B <- read.dbf(file.path(path, "forest_HUC010801_100ft2.dbf"))
names(B)[2:4] <- paste0(names(B)[2:4], "_100ft")
C <- read.dbf(file.path(path, "forest_HUC010801_200ft2.dbf"))
names(C)[2:4] <- paste0(names(C)[2:4], "_200ft")
D <- left_join(A, B, by = "FEATUREID") %>%
left_join(C, by = "FEATUREID")
path <- "C:/KPONEIL/riparianBufferErrors/dbfTables"
A <- read.dbf(file.path(path, "forest_HUC010801_50ft2.dbf"))
names(A)[2:4] <- paste0(names(A)[2:4], "_50ft")
B <- read.dbf(file.path(path, "forest_HUC010801_100ft2.dbf"))
names(B)[2:4] <- paste0(names(B)[2:4], "_100ft")
C <- read.dbf(file.path(path, "forest_HUC010801_200ft2.dbf"))
names(C)[2:4] <- paste0(names(C)[2:4], "_200ft")
D <- left_join(A, B, by = "FEATUREID") %>%
left_join(C, by = "FEATUREID")
int <- D[which(D$AREA_50ft >= D$AREA_200ft),]
int
Z <- read.dbf(file.path(path, "forest_HUC010801_100ft3.dbf"))
names(A)[2:4] <- paste0(names(A)[2:4], "_50ft")
Y <- read.dbf(file.path(path, "forest_HUC010801_100ft2.dbf"))
names(B)[2:4] <- paste0(names(B)[2:4], "_100ft")
X <- left_join(Z, Y, by = "FEATUREID")
int <- D[which(D$AREA_100ft.x != D$AREA_100ft.y),]
int <- X[which(X$AREA_100ft.x != X$AREA_100ft.y),]
int
head(z)
head(Z)
head(Y)
head(X)
int <- X[which(X$AREA.x != X$AREA.y),]
int
Z <- read.dbf(file.path(path, "forest_HUC010801_100ft4.dbf"))
names(A)[2:4] <- paste0(names(A)[2:4], "_50ft")
Y <- read.dbf(file.path(path, "forest_HUC010801_100ft2.dbf"))
names(B)[2:4] <- paste0(names(B)[2:4], "_100ft")
X <- left_join(Z, Y, by = "FEATUREID")
int <- X[which(X$AREA.x != X$AREA.y),]
int
path <- "C:/KPONEIL/riparianBufferErrors/dbfTables"
A <- read.dbf(file.path(path, "forest_HUC010801_50ft3.dbf"))
names(A)[2:4] <- paste0(names(A)[2:4], "_50ft")
B <- read.dbf(file.path(path, "forest_HUC010801_100ft3.dbf"))
names(B)[2:4] <- paste0(names(B)[2:4], "_100ft")
C <- read.dbf(file.path(path, "forest_HUC010801_200ft3.dbf"))
names(C)[2:4] <- paste0(names(C)[2:4], "_200ft")
D <- left_join(A, B, by = "FEATUREID") %>%
left_join(C, by = "FEATUREID")
int <- D[which(D$AREA_50ft >= D$AREA_200ft),]
out <- D[which(D$AREA_50ft != D$AREA_200ft),]
int
head(A)
dim(A)
dim(B)
dim(C)
length(unique(C$FEATUREID)
)
length(unique(B$FEATUREID))
length(unique(C$FEATUREID))
length(unique(A$FEATUREID))
D
length(unique(A$FEATUREID))
length(unique(B$FEATUREID))
length(unique(C$FEATUREID))
head(D)
D[which(is.na(D$AREA_50ft)),]
range(D$AREA_50ft)
summary(D$AREA_50ft)
dim(D)
D <- left_join(C, B, by = "FEATUREID") %>%
left_join(A, by = "FEATUREID")
D[which(is.na(D$AREA_50ft)),]
int
A[which(A$FEATUREID == 773413),]
B[which(B$FEATUREID == 773413),]
C[which(C$FEATUREID == 773413),]
4500/30
8100/30
23400/30
path <- "C:/KPONEIL/riparianBufferErrors/dbfTables"
A <- read.dbf(file.path(path, "forest_HUC010801_50ftX.dbf"))
names(A)[2:4] <- paste0(names(A)[2:4], "_50ft")
B <- read.dbf(file.path(path, "forest_HUC010801_200ftX.dbf"))
names(B)[2:4] <- paste0(names(B)[2:4], "_200ft")
D <- left_join(A, B, by = "FEATUREID")
int <- D[which(D$AREA_50ft >= D$AREA_200ft),]
int
A <- read.dbf(file.path(path, "forest_HUC010801_50ftXrastExt.dbf"))
names(A)[2:4] <- paste0(names(A)[2:4], "_50ft")
B <- read.dbf(file.path(path, "forest_HUC010801_200ftXrastExt.dbf"))
names(B)[2:4] <- paste0(names(B)[2:4], "_200ft")
D <- left_join(A, B, by = "FEATUREID")
int <- D[which(D$AREA_50ft >= D$AREA_200ft),]
int
path <- "C:/KPONEIL/riparianBufferErrors/dbfTables"
A <- read.dbf(file.path(path, "forest_HUC010801_50ft_rastExt.dbf"))
names(A)[2:4] <- paste0(names(A)[2:4], "_50ft")
B <- read.dbf(file.path(path, "forest_HUC010801_200ft_rastExt.dbf"))
names(B)[2:4] <- paste0(names(B)[2:4], "_200ft")
D <- left_join(A, B, by = "FEATUREID")
int <- D[which(D$AREA_50ft >= D$AREA_200ft),]
int
int <- D[which(D$AREA_50ft >= D$AREA_200ft+900),]
int
int <- D[which(D$AREA_50ft >= D$AREA_200ft-900),]
int
dim(D)
int <- D[which(D$AREA_50ft >= D$AREA_200ft/2),]
dim(int)
int
int <- D[which(D$AREA_50ft >= D$AREA_200ft/4),]
dim(int)
16*8000
128000/3600
A <- read.dbf(file.path(path, "forest_HUC010801_50ft_polyExt.dbf"))
names(A)[2:4] <- paste0(names(A)[2:4], "_50ft")
B <- read.dbf(file.path(path, "forest_HUC010801_200ft_polyExt.dbf"))
names(B)[2:4] <- paste0(names(B)[2:4], "_200ft")
D <- left_join(A, B, by = "FEATUREID")
path <- "C:/KPONEIL/riparianBufferErrors/dbfTables"
A <- read.dbf(file.path(path, "forest_HUC010801_50ft_polyExt.dbf"))
file.path(path, "forest_HUC010801_50ft_polyExt.dbf")
A <- read.dbf(file.path(path, "forest_HUC010801_50ft_polyExt.dbf"))
A <- read.dbf(file.path(path, "forest_HUC010801_50ft_polyExt.dbf"))
A <- read.dbf(file.path(path, "forest_HUC010801_50ft_polytExt.dbf"))
names(A)[2:4] <- paste0(names(A)[2:4], "_50ft")
B <- read.dbf(file.path(path, "forest_HUC010801_200ft_polyExt.dbf"))
B <- read.dbf(file.path(path, "forest_HUC010801_200ft_polytExt.dbf"))
names(B)[2:4] <- paste0(names(B)[2:4], "_200ft")
D <- left_join(A, B, by = "FEATUREID")
int <- D[which(D$AREA_50ft >= D$AREA_200ft/4),]
int
int <- D[which(D$AREA_50ft >= D$AREA_200ft),]
int
int <- D[which(D$AREA_50ft >= D$AREA_200ft/2),]
int
A <- read.dbf(file.path(path, "forest_HUC010801_50ft_rasttExt.dbf"))
A <- read.dbf(file.path(path, "forest_HUC010801_50ft_rastExt.dbf"))
B <- read.dbf(file.path(path, "forest_HUC010801_50ft_polytExt.dbf"))
dim(A)
dim(B)
A <- read.dbf(file.path(path, "forest_HUC010801_50ft_rastExt.dbf"))
B <- read.dbf(file.path(path, "forest_HUC010801_50ft_actualAreas.dbf"))
head(A)
head(B)
C <- left_join(A, B, by = 'FEATUREID')
head(C)
C <- left_join(A, B, by = 'FEATUREID') %>%
mutate(diff = AREA - Shape_Area)
head(C)
hist(C$diff)
hist(C$diff)
max(C$diff)
C[which(C$diff = max(C$diff)),]
C[which(C$diff == max(C$diff)),]
C <- left_join(A, B, by = 'FEATUREID') %>%
mutate(diff = Shape_Area - AREA) %>%
mutate(pctDiff = diff/Shape_Area)
head(C)
range(pctDiff)
range(C$pctDiff)
C <- left_join(A, B, by = 'FEATUREID') %>%
mutate(diff = Shape_Area - AREA) %>%
mutate(pctDiff = diff/Shape_Area*100)%>%
mutate(absPctDiff = abs(pctDiff))
head(C)
D <- filter(C, absPctDiff > 10)
dim(D)
D
D <- filter(C, absPctDiff > 10)%>%
select(AREA, Shape_Area, pctDiff)
D
D <- filter(C, absPctDiff > 10)%>%
select(FEATUREID, AREA, Shape_Area, pctDiff)
D
D <- filter(C, absPctDiff > 25)%>%
select(FEATUREID, AREA, Shape_Area, pctDiff)
D
dim(C)
rm(list=ls())
# Catchment Stats Generator
library(dplyr)
library(reshape2)
# ======
# Inputs
# ======
baseDirectory <- 'C:/KPONEIL/GitHub/projects/basinCharacteristics/zonalStatistics'
# There are 3 options for specifying the variables to output:
#   1) "ALL" will include all of the variables present in the folder
#   2) NULL will include the variables from the "rasterList" object in the "HRD_INPUTS.txt" file
#   3) Manually list the variables to output
outputVariables <- c("ALL")
activateThreshold <- TRUE
missingDataThreshold <- 80
source( file.path(baseDirectory, "scripts", "HRD_INPUTS.txt") )
# ==================
# Conversion Factors
# ==================
# Read the conversion factors file
setwd(baseDirectory); setwd('..')
conversionFactors <- read.csv("Covariate Data Status - High Res Delineation.csv")[,c("Name", "Conversion.Factor")]
# Rename columns
names(conversionFactors) <- c("variable", "factor")
outputVariables
# Create list of variables to compile
if ( all(outputVariables %in% "ALL" == TRUE) ){
localStatFiles <- list.files(path = rTablesDirectory, pattern = "local_")
}else{
localStatFiles <- c()
for( LF in seq_along(outputVariables) ){
localStatFiles <- c(localStatFiles, list.files(path = rTablesDirectory, pattern = paste0("local_",outputVariables[LF] ) ) )
}
}
# ======================
# Group stats for output
# ======================
# Set the directory where the tables are located
rTablesDirectory <- file.path(baseDirectory, "versions", outputName, "rTables")
if(is.null(outputVariables)){outputVariables <- c(discreteRasters, continuousRasters)}
# Catchment Stats Generator
library(dplyr)
library(reshape2)
# ======
# Inputs
# ======
baseDirectory <- 'C:/KPONEIL/GitHub/projects/basinCharacteristics/zonalStatistics'
# There are 3 options for specifying the variables to output:
#   1) "ALL" will include all of the variables present in the folder
#   2) NULL will include the variables from the "rasterList" object in the "HRD_INPUTS.txt" file
#   3) Manually list the variables to output
outputVariables <- c("ALL")
outputVariables <- c("undev_forest")
activateThreshold <- TRUE
missingDataThreshold <- 80
# ========================
# Read user-defined inputs
# ========================
source( file.path(baseDirectory, "scripts", "HRD_INPUTS.txt") )
# ==================
# Conversion Factors
# ==================
# Read the conversion factors file
setwd(baseDirectory); setwd('..')
conversionFactors <- read.csv("Covariate Data Status - High Res Delineation.csv")[,c("Name", "Conversion.Factor")]
# Rename columns
names(conversionFactors) <- c("variable", "factor")
# ======================
# Group stats for output
# ======================
# Set the directory where the tables are located
rTablesDirectory <- file.path(baseDirectory, "versions", outputName, "rTables")
if(is.null(outputVariables)){outputVariables <- c(discreteRasters, continuousRasters)}
# Local
# -----
# Create list of variables to compile
if ( all(outputVariables %in% "ALL" == TRUE) ){
localStatFiles <- list.files(path = rTablesDirectory, pattern = "local_")
}else{
localStatFiles <- c()
for( LF in seq_along(outputVariables) ){
localStatFiles <- c(localStatFiles, list.files(path = rTablesDirectory, pattern = paste0("local_",outputVariables[LF] ) ) )
}
}
# Loop through files. Pull data and join together for output.
for ( L in seq_along(localStatFiles) ){
# Print status
print(L)
# Read in CSV
localTemp <- read.csv(file.path(rTablesDirectory, localStatFiles[L]) )
# If the percent of the area with data does not meet the threshold, then convert to NA
if ( "percentAreaWithData" %in% names(localTemp) & activateThreshold ){
localTemp[which(localTemp$percentAreaWithData < missingDataThreshold), "MEAN"] <- NA
localTemp <- select(localTemp, -percentAreaWithData)
}
# Get file name
A <- gsub("*local_", "", localStatFiles[L])
variableName <- gsub(paste0("*_", statType,".csv"), "", A)
variableName <- gsub(paste0("*.csv"), "", variableName)
# Rename the columns. Account for the variables without the "percentAreaWithData" metric
if(ncol(localTemp) == 3) {names(localTemp) <- c(zoneField, variableName, paste0(variableName, "_percentAreaWithData"))} else(names(localTemp) <- c(zoneField, variableName))
# Pull the variable specifc factor
factor <- filter(conversionFactors, variable == variableName)%>%
select(factor)
# Account for missing factors
if(is.na(as.numeric(factor))) {
print(paste0("Factor missing for '", variableName, "'. Assigning a default factor of 1."))
factor <- 1
}
# Multiply the raw variable value by the conversion factor
localTemp[,names(localTemp) == variableName] <- localTemp[,names(localTemp) == variableName]*as.numeric(factor)
# Join to main dataframe
if( L == 1) {LocalStats <- localTemp} else(LocalStats <- left_join(LocalStats, localTemp, by = zoneField) )
}
head(LocalStats)
head(localTemp)
localTemp <- read.csv(file.path(rTablesDirectory, localStatFiles[L]) )
head(localTemp)
rm(list=ls())
# Catchment Stats Generator
library(dplyr)
library(reshape2)
# ======
# Inputs
# ======
baseDirectory <- 'C:/KPONEIL/GitHub/projects/basinCharacteristics/zonalStatistics'
# There are 3 options for specifying the variables to output:
#   1) "ALL" will include all of the variables present in the folder
#   2) NULL will include the variables from the "rasterList" object in the "HRD_INPUTS.txt" file
#   3) Manually list the variables to output
outputVariables <- c("ALL")
outputVariables <- c("undev_forest")
activateThreshold <- TRUE
missingDataThreshold <- 80
# ========================
# Read user-defined inputs
# ========================
source( file.path(baseDirectory, "scripts", "HRD_INPUTS.txt") )
# ==================
# Conversion Factors
# ==================
# Read the conversion factors file
setwd(baseDirectory); setwd('..')
conversionFactors <- read.csv("Covariate Data Status - High Res Delineation.csv")[,c("Name", "Conversion.Factor")]
# Rename columns
names(conversionFactors) <- c("variable", "factor")
# ======================
# Group stats for output
# ======================
# Set the directory where the tables are located
rTablesDirectory <- file.path(baseDirectory, "versions", outputName, "rTables")
if(is.null(outputVariables)){outputVariables <- c(discreteRasters, continuousRasters)}
# Local
# -----
# Create list of variables to compile
if ( all(outputVariables %in% "ALL" == TRUE) ){
localStatFiles <- list.files(path = rTablesDirectory, pattern = "local_")
}else{
localStatFiles <- c()
for( LF in seq_along(outputVariables) ){
localStatFiles <- c(localStatFiles, list.files(path = rTablesDirectory, pattern = paste0("local_",outputVariables[LF] ) ) )
}
}
# Loop through files. Pull data and join together for output.
for ( L in seq_along(localStatFiles) ){
# Print status
print(L)
# Read in CSV
localTemp <- read.csv(file.path(rTablesDirectory, localStatFiles[L]) )
# If the percent of the area with data does not meet the threshold, then convert to NA
if ( "percentAreaWithData" %in% names(localTemp) & activateThreshold ){
localTemp[which(localTemp$percentAreaWithData < missingDataThreshold), "MEAN"] <- NA
localTemp <- select(localTemp, -percentAreaWithData)
}
# Get file name
A <- gsub("*local_", "", localStatFiles[L])
variableName <- gsub(paste0("*_", statType,".csv"), "", A)
variableName <- gsub(paste0("*.csv"), "", variableName)
# Rename the columns. Account for the variables without the "percentAreaWithData" metric
if(ncol(localTemp) == 3) {names(localTemp) <- c(zoneField, variableName, paste0(variableName, "_percentAreaWithData"))} else(names(localTemp) <- c(zoneField, variableName))
# Pull the variable specifc factor
factor <- filter(conversionFactors, variable == variableName)%>%
select(factor)
# Account for missing factors
if(is.na(as.numeric(factor))) {
print(paste0("Factor missing for '", variableName, "'. Assigning a default factor of 1."))
factor <- 1
}
# Multiply the raw variable value by the conversion factor
localTemp[,names(localTemp) == variableName] <- localTemp[,names(localTemp) == variableName]*as.numeric(factor)
# Join to main dataframe
if( L == 1) {LocalStats <- localTemp} else(LocalStats <- left_join(LocalStats, localTemp, by = zoneField) )
}
# Upstream
# --------
# Create list of variables to compile
if ( all(outputVariables %in% "ALL" == TRUE) ){
upstreamStatFiles <- list.files(path = rTablesDirectory, pattern = "upstream_")
}else{
upstreamStatFiles <- c()
for( UF in seq_along(outputVariables) ){
upstreamStatFiles <- c(upstreamStatFiles, list.files(path = rTablesDirectory, pattern = paste0("upstream_",outputVariables[UF] ) ) )
}
}
# Loop through files. Pull data and join together for output.
for ( U in 1:length(upstreamStatFiles) ){
# Print status
print(U)
# Read in CSV
upstreamTemp <- read.csv(file.path(rTablesDirectory, upstreamStatFiles[U]) )
# If the percent of the area with data does not meet the threshold, then convert to NA
if ( "percentAreaWithData" %in% names(upstreamTemp) & activateThreshold ){
upstreamTemp[which(upstreamTemp$percentAreaWithData < missingDataThreshold), "MEAN"] <- NA
upstreamTemp <- select(upstreamTemp, -percentAreaWithData)
}
# Get file name
A <- gsub("*upstream_", "", upstreamStatFiles[U])
variableName <- gsub(paste0("*_", statType,".csv"), "", A)
variableName <- gsub(paste0("*.csv"), "", variableName)
# Rename the columns. Account for the variables without the "percentAreaWithData" metric
if(ncol(upstreamTemp) == 3) {names(upstreamTemp) <- c(zoneField, variableName, paste0(variableName, "_percentAreaWithData"))}
else(names(upstreamTemp) <- c(zoneField, variableName))
# Pull the variable specific factor
factor <- filter(conversionFactors, variable == variableName)%>%
select(factor)
# Account for missing factors
if(is.na(as.numeric(factor))) {
print(paste0("Factor missing for '", variableName, "'. Assigning a default factor of 1."))
factor <- 1
}
# Multiply the raw variable value by the conversion factor
upstreamTemp[,names(upstreamTemp) == variableName] <- upstreamTemp[,names(upstreamTemp) == variableName]*as.numeric(factor)
# Join to main dataframe
if( U == 1) {UpstreamStats <- upstreamTemp} else(UpstreamStats <- left_join(UpstreamStats, upstreamTemp, by = zoneField) )
}
# Format for Database
# -------------------
locLong <- melt(LocalStats,'FEATUREID')
locLong$zone <- "local"
upLong <- melt(UpstreamStats,'FEATUREID')
upLong$zone <- "upstream"
dbStats <- rbind(locLong, upLong)
#save(dbStats, file = file.path(baseDirectory, "versions", outputName, "completedStats", paste0("zonalStatsForDB_", Sys.Date(),".RData") ))
names(dbStats) <- tolower(names(dbStats))
head(dbStats)
range(dbStats$value)
unique(dbStats$value)
length(unique(dbStats$value))
stopifnot(all(names(dbStats) == c('featureid', 'variable', 'value', 'zone')))
write.csv(dbStats,
file = file.path(baseDirectory, "versions", outputName, "completedStats", paste0("zonalStatsForDB_undev_forest_correction", Sys.Date(),".csv") ),
row.names = FALSE)
