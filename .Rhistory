# File path to table
tableFilePath <- file.path(baseDirectory,"versions", outputName, "gisTables", paste0(rasterList[j], "_", statType, ".dbf"))
# Open table
dbfTable <-read.dbf(tableFilePath)[,c(zoneField, statType, "AREA")]
dbfTable$AREA <- dbfTable$AREA*0.000001 # convert to square kilometers
dbfTable[which(dbfTable[,statType] == -9999), statType] <- NA # Replace all "-9999" values with "NA"
# Output filepath
outputTable <- file.path(baseDirectory, "versions", outputName, "rTables", paste0("local_", rasterList[j], "_", statType, ".csv"))
if ( !file.exists(outputTable) ){
# Calculate the % of the catchment area with data and include in the output
gisStat <- left_join(dbfTable, rasterArea, by = zoneField) %>%
mutate(percentAreaWithData = AREA/AreaSqKM*100)%>%
select(-c(AREA, AreaSqKM))
# save this as a file
write.csv(gisStat, file = outputTable, row.names = F)
}
# Prep dataframes for upstream averaging
# --------------------------------------
# Data
dat <- dbfTable[,c(zoneField, statType)]
names(dat)[2] <- rasterList[j]
if ( j == 1 ) { zonalData <- dat } else( zonalData <- left_join(zonalData, dat, by = zoneField))
# Areas
wt <- dbfTable[,c(zoneField, "AREA")]
names(wt)[2] <- rasterList[j]
if ( j == 1 ) { zonalAreas <- wt } else( zonalAreas <- left_join(zonalAreas, wt, by = zoneField))
}
# ===========================
# Process upstream statistics
# ===========================
# Define features to compute
featureList <- zonalData[,zoneField]
# Define storage dataframes
# -------------------------
# Upstream stats
upstreamStats <- data.frame(matrix(NA, nrow = length(featureList), ncol = length(rasterList) + 1))
names(upstreamStats) <- c(zoneField, rasterList)
# Areas with data
pcntUpstreamWithData <- data.frame(matrix(NA, nrow = length(featureList), ncol = length(rasterList) + 1))
names(pcntUpstreamWithData) <- c(zoneField, rasterList)
# Upstream area (from vector)
areaFileUpstream <- file.path(baseDirectory, "versions", outputName, "rTables", paste0("upstream_AreaSqKM.csv"))
# If Upstream area file doesn't exist, calculate it based on the vectors
if ( !file.exists(areaFileUpstream) ){
upstreamArea <- data.frame(matrix(NA, nrow = length(featureList), ncol = 2))
names(upstreamArea) <- c(zoneField, "AreaSqKM")
}
# Catchments loop
# ---------------
progressBar <- tkProgressBar(title = "progress bar", min = 0, max = length(featureList), width = 300)
for ( m in seq_along(featureList)){
# Get features in current basin
features <- delineatedCatchments[[which(names(delineatedCatchments) == featureList[m])]]
# Sum the areas of the individual catchments in the basin (raster version)
TotDASqKM <- sum(filter_(rasterArea, interp(~col %in% features, col = as.name(zoneField)))$AreaSqKM)
# Get individual catchment stats for current basin
catchStats <- filter_(zonalData, interp(~col %in% features, col = as.name(zoneField)))#%>%
# Get individual catchment areas with data for current basin
catchAreas <- filter_(zonalAreas, interp(~col %in% features, col = as.name(zoneField)))#%>%
# Calculate the weights of each element in the dataframe (creates a matching dataframe)
weights <- sweep(catchAreas, 2, colSums(catchAreas), `/`)
# Sum the weighted stats to get final values
outStats <- colSums(catchStats*weights, na.rm = T)
# Get the percentage of catchment area with data
outAreas <- colSums(catchAreas)/TotDASqKM
# Account for the rare case of catchments area = 0 (product of rasterizing catchments polygons)
if (TotDASqKM == 0) {
outStats[2:length(outStats)] <- NA
outAreas[2:length(outAreas)] <- 0
}
# Upstream stats
upstreamStats[m,1]                     <- featureList[m]
upstreamStats[m,2:ncol(upstreamStats)] <- outStats[-1]
# Area with data
pcntUpstreamWithData[m,1]                     <- featureList[m]
pcntUpstreamWithData[m,2:ncol(upstreamStats)] <- outAreas[-1]
# Total drainage area
# -------------------
# This is calculated based on the vector file
if ( !file.exists(areaFileUpstream) ){
upstreamArea[m,1] <- featureList[m]
upstreamArea[m,2] <- sum(filter_(vectorArea, interp(~col %in% features, col = as.name(zoneField)))$AreaSqKM, na.rm = T)
}
# Progress bar update
setTkProgressBar(progressBar, m, label=paste( round(m/length(featureList)*100, 2), "% done"))
}
close(progressBar)
# Output upstream statistics tables
# ---------------------------------
# Loop through variables writing tables with upstream data and the percent of the area with data
for ( n in 2:(ncol(upstreamStats))){
# Name
colName <- names(upstreamStats)[n]
# Output dataframe
upStat <- upstreamStats[,c(zoneField, colName)]
names(upStat)[2] <- statType
upPcnt <- pcntUpstreamWithData[,c(zoneField, colName)]
upPcnt[,2] <- upPcnt[,2]*100
names(upPcnt)[2] <- "percentAreaWithData"
up <- left_join(upStat, upPcnt, by = zoneField)
outputUpstream  <- file.path(baseDirectory, "versions", outputName, "rTables", paste0("upstream_", colName, "_", statType, ".csv"))
write.csv(up, file = outputUpstream,  row.names = F)
}
# Save area file
if ( !file.exists(areaFileUpstream) ){
write.csv(upstreamArea, file = areaFileUpstream, row.names = F)
}
seq_along(rasterList)
rm(list=ls())
library(dplyr)
rasterList <- c("forest", "agriculture", "impervious", "fwswetlands", "fwsopenwater", "slope_pcnt", "elevation", "surfcoarse", "percent_sandy", "drainclass", "hydrogroup_ab")
tableFolder <- "C:/KPONEIL/GitHub/projects/basinCharacteristics/zonalStatistics/versions/pointDelineation/gisTables"
rasterData <- NULL
zoneField <- "DelinID"
rasterData <- NULL
for (r in seq_along(rasterList)){
inTable <- read.dbf(file.path(tableFolder, paste0(rasterList[r], ".dbf"))))
if( is.null(rasterData)){rasterData <- inTable} else(rasterData <- left_join(rasterData, inTable, ))
}
is.null(rasterData)
for (r in seq_along(rasterList)){
inTable <- read.dbf(file.path(tableFolder, paste0(rasterList[r], ".dbf")))
if(is.null(rasterData)){rasterData <- inTable} else(rasterData <- left_join(rasterData, inTable, ))
}
library(foreign)
rasterData <- NULL
for (r in seq_along(rasterList)){
inTable <- read.dbf(file.path(tableFolder, paste0(rasterList[r], ".dbf")))
if(is.null(rasterData)){rasterData <- inTable} else(rasterData <- left_join(rasterData, inTable, ))
}
rasterData <- NULL
for (r in seq_along(rasterList)){
inTable <- read.dbf(file.path(tableFolder, paste0(rasterList[r], ".dbf")))
if(is.null(rasterData)){rasterData <- inTable} else(rasterData <- left_join(rasterData, inTable, zoneField))
}
paste0(rasterList[r], ".dbf")
rasterList <- c("forest", "agriculture", "impervious", "fwswetlands", "fwsopenwater", "slope_pcnt", "elevation", "surfcoarse", "percent_sandy", "drainageclass", "hydrogroup_ab")
# Rasters
# -------
rasterData <- NULL
for (r in seq_along(rasterList)){
inTable <- read.dbf(file.path(tableFolder, paste0(rasterList[r], ".dbf")))
if(is.null(rasterData)){rasterData <- inTable} else(rasterData <- left_join(rasterData, inTable, zoneField))
}
head(rasterData)
catchmentsFilePath <- "C:/KPONEIL/delineation/northeast/pointDelineation/outputFiles/delin_basins_deerfield_2_17_2015.shp"
shapeAttributes <- read.dbf(catchmentsFilePath)
catchmentsFilePath <- "C:/KPONEIL/delineation/northeast/pointDelineation/outputFiles/delin_basins_deerfield_2_17_2015.dbf"
shapeAttributes <- read.dbf(catchmentsFilePath)
head(shapeAttributes)
dim(shapeAttributes)
dim(rasterData)
areas <- read.dbf(catchmentsFilePath)[,c(zoneField, "AreaSqKM")]
head(areas)
areas[areas$DelinID == 100000,]
areas[areas$DelinID == 100058,]
j = 1
tableFilePath <- read.dbf(file.path(tableFolder, paste0(rasterList[j], ".dbf")))
dbfTable <-read.dbf(tableFilePath)[,c(zoneField, statType, "AREA")]
tableFilePath <- file.path(tableFolder, paste0(rasterList[j], ".dbf"))
dbfTable <-read.dbf(tableFilePath)[,c(zoneField, statType, "AREA")]
head(inTable)
statType = "MEAN"
dbfTable <-read.dbf(tableFilePath)[,c(zoneField, statType, "AREA")]
dbfTable
head(dbfTable)
dbfTable$AREA <- dbfTable$AREA*0.000001 # convert to square kilometers
dbfTable[which(dbfTable[,statType] == -9999), statType] <- NA # Replace all "-9999" values with "NA"
baseDirectory <- 'C:/KPONEIL/GitHub/projects/basinCharacteristics/zonalStatistics'
outputName <- "pointDelineation"
file.path(baseDirectory, "versions", outputName, "rTables", paste0("local_", rasterList[j], "_", statType, ".csv"))
file.path(baseDirectory, "versions", outputName, "rTables", paste0(rasterList[j], "_", statType, ".csv"))
shapeAreas <- read.dbf(catchmentsFilePath)[,c(zoneField, "AreaSqKM")]
j = 1
tableFilePath <- file.path(tableFolder, paste0(rasterList[j], ".dbf"))
# Open table
dbfTable <-read.dbf(tableFilePath)[,c(zoneField, statType, "AREA")]
dbfTable$AREA <- dbfTable$AREA*0.000001 # convert to square kilometers
dbfTable[which(dbfTable[,statType] == -9999), statType] <- NA # Replace all "-9999" values with "NA"
# Output filepath
outputTable <- file.path(baseDirectory, "versions", outputName, "rTables", paste0(rasterList[j], "_", statType, ".csv"))
!file.exists(outputTable)
gisStat <- left_join(dbfTable, shapeAreas, by = zoneField) %>%
mutate(percentAreaWithData = AREA/AreaSqKM*100)%>%
select(-c(AREA, AreaSqKM))
head(gisStat)
range(gisStat$percentAreaWithData)
rasterList[j]
hist(range(gisStat$percentAreaWithData))
gisStat
hist(gisStat$percentAreaWithData)
hist(gisStat$percentAreaWithData)
?hist
hist(gisStat$percentAreaWithData, breaks = 100)
min(gisStat$percentAreaWithData)
head(gisStat)
gisStat[which(gisStat$percentAreaWithData < 50),]
statType
names(gisStat)[which(names(gisStat) == statType)]
rasterList[j]
conversionValues <- c(     100,           100,            1,           100,            100,            1,           1,          100,             100,               1,             100)
outData <- gisStat[,c(zoneField, statType)]
head(outData)
names(outData)[which(names(outData) == statType)] <- rasterList[j]
head(outData)
percentAreasWithData <- gisStat[,c(zoneField, "percentAreaWithData")]
names(percentAreasWithData)[which(names(percentAreasWithData) ==  "percentAreaWithData")] <- rasterList[j]
head(percentAreasWithData)
outData[ ,rasterList[j]] <- outData[ ,rasterList[j]]*conversionValues[j]
head(outData)
c(zoneField, rasterList[j], paste0("percentAreaWithData_", rasterList[j])
)
head(gisData)
gisStat
head(gisStat)
pointDelineationStats <- NULL
# Loop through layers, reading files.
for (j in seq_along(rasterList)){
# File path to table
tableFilePath <- file.path(tableFolder, paste0(rasterList[j], ".dbf"))
# Open table
dbfTable <-read.dbf(tableFilePath)[,c(zoneField, statType, "AREA")]
dbfTable$AREA <- dbfTable$AREA*0.000001 # convert to square kilometers
dbfTable[which(dbfTable[,statType] == -9999), statType] <- NA # Replace all "-9999" values with "NA"
# Output filepath
outputTable <- file.path(baseDirectory, "versions", outputName, "rTables", paste0(rasterList[j], "_", statType, ".csv"))
if ( !file.exists(outputTable) ){
# Calculate the % of the catchment area with data and include in the output
gisStat <- left_join(dbfTable, shapeAreas, by = zoneField) %>%
mutate(percentAreaWithData = AREA/AreaSqKM*100)%>%
select(-c(AREA, AreaSqKM))
# save this as a file
write.csv(gisStat, file = outputTable, row.names = F)
} else (gisStat <- read.dbf(outputTable))
names(gisStat) <- c(zoneField, rasterList[j], paste0(rasterList[j]"_percentAreaWithData")
if(is.null(pointDelineationStats)){pointDelineationStats <- gisStat} else(pointDelineationStats <- left_join(pointDelineationStats, gisStat, zoneField))
}
c(zoneField, rasterList[j], paste0(rasterList[j], "_percentAreaWithData")
)
pointDelineationStats <- NULL
# Loop through layers, reading files.
for (j in seq_along(rasterList)){
# File path to table
tableFilePath <- file.path(tableFolder, paste0(rasterList[j], ".dbf"))
# Open table
dbfTable <-read.dbf(tableFilePath)[,c(zoneField, statType, "AREA")]
dbfTable$AREA <- dbfTable$AREA*0.000001 # convert to square kilometers
dbfTable[which(dbfTable[,statType] == -9999), statType] <- NA # Replace all "-9999" values with "NA"
# Output filepath
outputTable <- file.path(baseDirectory, "versions", outputName, "rTables", paste0(rasterList[j], "_", statType, ".csv"))
if ( !file.exists(outputTable) ){
# Calculate the % of the catchment area with data and include in the output
gisStat <- left_join(dbfTable, shapeAreas, by = zoneField) %>%
mutate(percentAreaWithData = AREA/AreaSqKM*100)%>%
select(-c(AREA, AreaSqKM))
# save this as a file
write.csv(gisStat, file = outputTable, row.names = F)
} else (gisStat <- read.dbf(outputTable))
names(gisStat) <- c(zoneField, rasterList[j], paste0(rasterList[j], "_percentAreaWithData"))
if(is.null(pointDelineationStats)){pointDelineationStats <- gisStat} else(pointDelineationStats <- left_join(pointDelineationStats, gisStat, zoneField))
}
head(pointDelineationStats)
pointDelineationStats <- shapeAreas
# Loop through layers, reading files.
for (j in seq_along(rasterList)){
# File path to table
tableFilePath <- file.path(tableFolder, paste0(rasterList[j], ".dbf"))
# Open table
dbfTable <-read.dbf(tableFilePath)[,c(zoneField, statType, "AREA")]
dbfTable$AREA <- dbfTable$AREA*0.000001 # convert to square kilometers
dbfTable[which(dbfTable[,statType] == -9999), statType] <- NA # Replace all "-9999" values with "NA"
# Output filepath
outputTable <- file.path(baseDirectory, "versions", outputName, "rTables", paste0(rasterList[j], "_", statType, ".csv"))
if ( !file.exists(outputTable) ){
# Calculate the % of the catchment area with data and include in the output
gisStat <- left_join(dbfTable, shapeAreas, by = zoneField) %>%
mutate(percentAreaWithData = AREA/AreaSqKM*100)%>%
select(-c(AREA, AreaSqKM))
# save this as a file
write.csv(gisStat, file = outputTable, row.names = F)
} else (gisStat <- read.dbf(outputTable))
names(gisStat) <- c(zoneField, rasterList[j], paste0(rasterList[j], "_percentAreaWithData"))
if(is.null(pointDelineationStats)){pointDelineationStats <- gisStat} else(pointDelineationStats <- left_join(pointDelineationStats, gisStat, zoneField))
}
r
rm(list=ls())
# Catchment Stats Generator
library(dplyr)
library(reshape2)
# ======
# Inputs
# ======
baseDirectory <- 'C:/KPONEIL/GitHub/projects/basinCharacteristics/zonalStatistics'
# There are 3 options for specifying the variables to output:
#   1) "ALL" will include all of the variables present in the folder
#   2) NULL will include the variables from the "rasterList" object in the "HRD_INPUTS.txt" file
#   3) Manually list the variables to output
outputVariables <- c("ALL")
activateThreshold <- TRUE
missingDataThreshold <- 80
# ========================
# Read user-defined inputs
# ========================
source( file.path(baseDirectory, "scripts", "HRD_INPUTS.txt") )
# ==================
# Conversion Factors
# ==================
# Read the conversion factors file
setwd(baseDirectory); setwd('..')
conversionFactors <- read.csv("Covariate Data Status - High Res Delineation.csv")[,c("Name", "Conversion.Factor")]
# Rename columns
names(conversionFactors) <- c("variable", "factor")
# ======================
# Group stats for output
# ======================
# Set the directory where the tables are located
rTablesDirectory <- file.path(baseDirectory, "versions", outputName, "rTables")
if(is.null(outputVariables)){outputVariables <- c(discreteRasters, continuousRasters)}
# Local
# -----
# Create list of variables to compile
if ( all(outputVariables %in% "ALL" == TRUE) ){
localStatFiles <- list.files(path = rTablesDirectory, pattern = "local_")
}else{
localStatFiles <- c()
for( LF in seq_along(outputVariables) ){
localStatFiles <- c(localStatFiles, list.files(path = rTablesDirectory, pattern = paste0("local_",outputVariables[LF] ) ) )
}
}
# Loop through files. Pull data and join together for output.
for ( L in seq_along(localStatFiles) ){
# Print status
print(L)
# Read in CSV
localTemp <- read.csv(file.path(rTablesDirectory, localStatFiles[L]) )
# If the percent of the area with data does not meet the threshold, then convert to NA
if ( "percentAreaWithData" %in% names(localTemp) & activateThreshold ){
localTemp[which(localTemp$percentAreaWithData < missingDataThreshold), "MEAN"] <- NA
}
# Get file name
A <- gsub("*local_", "", localStatFiles[L])
variableName <- gsub(paste0("*_", statType,".csv"), "", A)
variableName <- gsub(paste0("*.csv"), "", variableName)
# Rename the columns. Account for the variables without the "percentAreaWithData" metric
if(ncol(localTemp) == 3) {names(localTemp) <- c(zoneField, variableName, paste0(variableName, "_percentAreaWithData"))} else(names(localTemp) <- c(zoneField, variableName))
# Pull the variable specifc factor
factor <- filter(conversionFactors, variable == variableName)%>%
select(factor)
# Account for missing factors
if(is.na(as.numeric(factor))) {
print(paste0("Factor missing for '", variableName, "'. Assigning a default factor of 1."))
factor <- 1
}
# Multiply the raw variable value by the conversion factor
localTemp[,names(localTemp) == variableName] <- localTemp[,names(localTemp) == variableName]*as.numeric(factor)
# Join to main dataframe
if( L == 1) {LocalStats <- localTemp} else(LocalStats <- left_join(LocalStats, localTemp, by = zoneField) )
}
# Upstream
# --------
# Create list of variables to compile
if ( all(outputVariables %in% "ALL" == TRUE) ){
upstreamStatFiles <- list.files(path = rTablesDirectory, pattern = "upstream_")
}else{
upstreamStatFiles <- c()
for( UF in seq_along(outputVariables) ){
upstreamStatFiles <- c(upstreamStatFiles, list.files(path = rTablesDirectory, pattern = paste0("upstream_",outputVariables[UF] ) ) )
}
}
# Loop through files. Pull data and join together for output.
for ( U in 1:length(upstreamStatFiles) ){
# Print status
print(U)
# Read in CSV
upstreamTemp <- read.csv(file.path(rTablesDirectory, upstreamStatFiles[U]) )
# If the percent of the area with data does not meet the threshold, then convert to NA
if ( "percentAreaWithData" %in% names(upstreamTemp) & activateThreshold ){
upstreamTemp[which(upstreamTemp$percentAreaWithData < missingDataThreshold), "MEAN"] <- NA
}
# Get file name
A <- gsub("*upstream_", "", upstreamStatFiles[U])
variableName <- gsub(paste0("*_", statType,".csv"), "", A)
variableName <- gsub(paste0("*.csv"), "", variableName)
# Rename the columns. Account for the variables without the "percentAreaWithData" metric
if(ncol(upstreamTemp) == 3) {names(upstreamTemp) <- c(zoneField, variableName, paste0(variableName, "_percentAreaWithData"))}
else(names(upstreamTemp) <- c(zoneField, variableName))
# Pull the variable specific factor
factor <- filter(conversionFactors, variable == variableName)%>%
select(factor)
# Account for missing factors
if(is.na(as.numeric(factor))) {
print(paste0("Factor missing for '", variableName, "'. Assigning a default factor of 1."))
factor <- 1
}
# Multiply the raw variable value by the conversion factor
upstreamTemp[,names(upstreamTemp) == variableName] <- upstreamTemp[,names(upstreamTemp) == variableName]*as.numeric(factor)
# Join to main dataframe
if( U == 1) {UpstreamStats <- upstreamTemp} else(UpstreamStats <- left_join(UpstreamStats, upstreamTemp, by = zoneField) )
}
str(UpstreamStats)
locLong <- melt(LocalStats,'FEATUREID')
locLong$zone <- "local"
upLong <- melt(UpstreamStats,'FEATUREID')
upLong$zone <- "upstream"
head(locLong)
head(upLong)
dim(locLong)
dim(upLong)
L = 1
print(L)
localTemp <- read.csv(file.path(rTablesDirectory, localStatFiles[L]) )
localTemp <- read.csv(file.path(rTablesDirectory, localStatFiles[L]) )
if ( "percentAreaWithData" %in% names(localTemp) & activateThreshold ){
localTemp[which(localTemp$percentAreaWithData < missingDataThreshold), "MEAN"] <- NA
localTemp <- localTemp[,-"percentAreaWithData"]
}
if ( "percentAreaWithData" %in% names(localTemp) & activateThreshold ){
localTemp[which(localTemp$percentAreaWithData < missingDataThreshold), "MEAN"] <- NA
localTemp <- localTemp[,-c("percentAreaWithData")]
}
head(localTemp)
# If the percent of the area with data does not meet the threshold, then convert to NA
if ( "percentAreaWithData" %in% names(localTemp) & activateThreshold ){
localTemp[which(localTemp$percentAreaWithData < missingDataThreshold), "MEAN"] <- NA
localTemp <- select(localTemp, -percentAreaWithData)
}
head(localTemp)
for ( L in seq_along(localStatFiles) ){
# Print status
print(L)
# Read in CSV
localTemp <- read.csv(file.path(rTablesDirectory, localStatFiles[L]) )
# If the percent of the area with data does not meet the threshold, then convert to NA
if ( "percentAreaWithData" %in% names(localTemp) & activateThreshold ){
localTemp[which(localTemp$percentAreaWithData < missingDataThreshold), "MEAN"] <- NA
localTemp <- select(localTemp, -percentAreaWithData)
}
# Get file name
A <- gsub("*local_", "", localStatFiles[L])
variableName <- gsub(paste0("*_", statType,".csv"), "", A)
variableName <- gsub(paste0("*.csv"), "", variableName)
# Rename the columns. Account for the variables without the "percentAreaWithData" metric
if(ncol(localTemp) == 3) {names(localTemp) <- c(zoneField, variableName, paste0(variableName, "_percentAreaWithData"))} else(names(localTemp) <- c(zoneField, variableName))
# Pull the variable specifc factor
factor <- filter(conversionFactors, variable == variableName)%>%
select(factor)
# Account for missing factors
if(is.na(as.numeric(factor))) {
print(paste0("Factor missing for '", variableName, "'. Assigning a default factor of 1."))
factor <- 1
}
# Multiply the raw variable value by the conversion factor
localTemp[,names(localTemp) == variableName] <- localTemp[,names(localTemp) == variableName]*as.numeric(factor)
# Join to main dataframe
if( L == 1) {LocalStats <- localTemp} else(LocalStats <- left_join(LocalStats, localTemp, by = zoneField) )
}
str(LocalStats)
# Upstream
# --------
# Create list of variables to compile
if ( all(outputVariables %in% "ALL" == TRUE) ){
upstreamStatFiles <- list.files(path = rTablesDirectory, pattern = "upstream_")
}else{
upstreamStatFiles <- c()
for( UF in seq_along(outputVariables) ){
upstreamStatFiles <- c(upstreamStatFiles, list.files(path = rTablesDirectory, pattern = paste0("upstream_",outputVariables[UF] ) ) )
}
}
# Loop through files. Pull data and join together for output.
for ( U in 1:length(upstreamStatFiles) ){
# Print status
print(U)
# Read in CSV
upstreamTemp <- read.csv(file.path(rTablesDirectory, upstreamStatFiles[U]) )
# If the percent of the area with data does not meet the threshold, then convert to NA
if ( "percentAreaWithData" %in% names(upstreamTemp) & activateThreshold ){
upstreamTemp[which(upstreamTemp$percentAreaWithData < missingDataThreshold), "MEAN"] <- NA
upstreamTemp <- select(upstreamTemp, -percentAreaWithData)
}
# Get file name
A <- gsub("*upstream_", "", upstreamStatFiles[U])
variableName <- gsub(paste0("*_", statType,".csv"), "", A)
variableName <- gsub(paste0("*.csv"), "", variableName)
# Rename the columns. Account for the variables without the "percentAreaWithData" metric
if(ncol(upstreamTemp) == 3) {names(upstreamTemp) <- c(zoneField, variableName, paste0(variableName, "_percentAreaWithData"))}
else(names(upstreamTemp) <- c(zoneField, variableName))
# Pull the variable specific factor
factor <- filter(conversionFactors, variable == variableName)%>%
select(factor)
# Account for missing factors
if(is.na(as.numeric(factor))) {
print(paste0("Factor missing for '", variableName, "'. Assigning a default factor of 1."))
factor <- 1
}
# Multiply the raw variable value by the conversion factor
upstreamTemp[,names(upstreamTemp) == variableName] <- upstreamTemp[,names(upstreamTemp) == variableName]*as.numeric(factor)
# Join to main dataframe
if( U == 1) {UpstreamStats <- upstreamTemp} else(UpstreamStats <- left_join(UpstreamStats, upstreamTemp, by = zoneField) )
}
locLong <- melt(LocalStats,'FEATUREID')
locLong$zone <- "local"
upLong <- melt(UpstreamStats,'FEATUREID')
upLong$zone <- "upstream"
str(upLong)
head(upLong)
head(locLong)
dim(upLong)
dim(locLong)
dbStats <- rbind(locLong[1:10], upLong[1:10])
dbStats <- rbind(locLong[1:10,], upLong[1:10,])
head(dbStats)
dbStats
